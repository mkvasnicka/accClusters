TODO
====

Now
---

- tvorba profilů
    - automatic time windows se nesmí do profilu zapsat natvrdo, protože pak by
        to bez změny profilů pokaždé generovalo pro stejné roky
        - to znamená změnu struktury profilů
    - funkce pro automatická časová okna se musejí zobecnit + musí se přesunout
        do auxiliary_function
    - každý skript, který pracuje s časovými okny si musí časová okna znovu
        poskládat
    - vyhodit nepoužívané testovací funkce?
    - vyhodit zakomentovaný kód
- grid_shape v NKDE dořešit s autorem balíku
    - teď to má provizorní řešení -- tinkering s gridem
- create_osm_districts používá na tvrdo konstantu districs_in_one_one=10
    - zjisit, co to dělá ~ jak osmium-extract používá paměť
    - přidat do uživatelského configu
- available_memory() -- doplnit pro docker
- available_cores() -- doplnit pro docker
- PWALK() zůstane někdy (při accidents?) viset -- proč?
    - ukončí otevřené soubory, přejde na 1 jádro, tam běží na 100 %, ale nic se
        neděje (tedy nic očividného)
    - opravil by to schedulling?
    - vyzkoušet na notebooku -- tam se to imho nedělo (je to možné?)
- aktualizovat export do GISu
- profily
    - přidat komentář, který se zobrazí v shiny
    - exportovat do shiny
- tvorba nehod -- kontrola, že obsahuje sloupce P44 a asi i P6



Big Picture
-----------
- proč spadly výpočty hustot?
    - původně
        - data/tmp/densities/densities_CZ0532_default_2019-01-01_2021-12-31.rds,
        - data/tmp/densities/densities_CZ0532_default_2016-01-01_2018-12-31.rds,
        - data/tmp/densities/densities_CZ0643_default_2019-01-01_2021-12-31.rds,
        - data/tmp/densities/densities_CZ0643_default_2016-01-01_2018-12-31.rds
    - nově
        - data/tmp/densities/densities_CZ0324_default_2019-01-01_2021-12-31.rds,
        - data/tmp/densities/densities_CZ0324_default_2016-01-01_2018-12-31.rds,
        - data/tmp/densities/densities_CZ0712_default_2016-01-01_2018-12-31.rds,
        - data/tmp/densities/densities_CZ0805_default_2019-01-01_2021-12-31.rds,
        - data/tmp/densities/densities_CZ0805_default_2016-01-01_2018-12-31.rds
- densities neloguje chyby do souboru (když spadne???)
- fixovat parametry tvorby klastrů -- shiny je musí mít fixní, takže je uživatel
  nemůže měnit
- napsat nápovědu pro parametry tvorby klastrů + profily
- zkontrolovat kód
- napsat dokumentaci
- docker + integrovat detekci paměti + cpu uvnitř dockeru
    - mám kód, ale zatím ho nepoužívám



Tvorba klastrů
--------------

- najít nějaké kritérium, jak stanovil kvantil a počet kroků rozšíření
    - PAI nefunguje ani na accident_cost, ani na densities

- kontrola: klastry jsou stejné pro profil default a other -- to je divné



Refactoring
-----------

- pročistit kód

- vyhodit:
    - process_command_line_arguments()
    - unit_cost(s)()
    - handle_time_widnow()

- zafixovat adresářovou strukturu tak, aby stačilo zadat začátky cest
    - společný začátek cesty: DIR_ORIGIN
    - alternativní začátky cest: RAW_DATA_DIR, DATA_DIR, OUTPUT_DIR a LOG_DIR
    - hotovo:
        - zrušeny staré konstanty
        - zavedeny nové funkce
    - nutno zkontrolovat

- guts_config.R bude pevně v jádře
    - parametry, které zadají uživatelé se budou volat v bashi přes --profile
    - přejmenovat --profile na --config

- process_command_line_arguments() předpokládá, že profily jsou podadresář guts --
  změnit

- PWALK by mělo throw exception, když selže
    - je potřeba najít všechna místa, kde se používá, a podívat se, jestli jsou v tryCatch()

- rozmyslet, jaké sloupce by měly obsahovat tabulky nehod + ty, které používáme, standardizovat
    - pro případ, že policie sloupce přejmenuje -- není kulturní, abychom používali jejich interní značky
    - nutné domluvit se Štěpánem, co z toho použije
        - data by to mělo chystat i pro něj -- aby se vzala data z guts a šoupla do shiny app

- rozmyslet si, jestli můžeme chtít, aby se uvažovalo víc různých typů nákladů nehod -- teď je to naimplementované částečně a asi nekonzistentně
    - tabulka accidents může mít víc sloupců pro náklady nehody
    - tabulka densities má jen jeden sloupec pro hustotu, která se počítá z nákladů
        - používá se to, co je zadané v NKDE_WEIGHTS (implicitně "accident_cost")
    - tabulka klastrů volá náklady
        - nepřímo přes density -- není jasné, jaké náklady se tu používají
        - přímo přes hodnotu klastru, která se bere z nehod -- současný kód neumožňuje zadat
    - otázka, jak to funguje s profily -- nemění pojmenované profily jména souborů?
        - a pokud ano, funguje to konzistentně?

- při exportu do shiny ořezat lixely a klastry na okres
    - lixely nechat jen ty, které jsou uvnitř skutečného okresu
    - klastry nechat celé, které aspoň částí zasahují do okresu

- policajti můžou chtít několik různých vah nehod -- nebo koneckonců jiného nastavení
    - návrh nového řešení -- profily, které se všechny vytvoří
    - nově začíná řešit skript guts/functions_profiles.R
    - moje představa je taková, že uživatel bude mít někde nějaký konfigurační soubor a profily
    - prvně se načte guts_config, pak uživatelská konfigurace a pak profil
        - profil tak může přepsat automatická nastavení
        - profilů může být víc
        - pokud žádný není, vytvoří se profil default
        - nastavení profilů se musí exportovat do shiny souboru
        - asi se musí vyexportovat i zvlášť, aby shiny vědělo, co má tak zhruba k dispozici
    - všechny skripty se musí upravit tak, že se nejdřív vyexportuje seznam profilů, a pak
        všechny skripty vytvoří nejen data pro okres nebo okres x čas, ale místo toho
        okres x profil nebo okres x čas x profil
        - musí se projevit je jménu výstupu
    - co je hotové
        - nástřel načítání a kontroly profilů
        - zatím ale nenačítá ani guts_config, ani uživatelský konfig
    - dodělat
        - načítání guts_config a uživatelský config
        - vlastní zpracování
    - toto by mělo nahradit různé váhy nehod, které jsou v současnosti v kódu + profily
    - PROBLÉM: různé profily se mohou lišit v různých stádiích výpočtu: v tvorbě map
        (délka lixelů etc.), výpočtu hustot (nastavení NKDE), určení klastrů
        - co s tím???

- výpočty klastrů jsou tak rychlé, že by se možná mohly přesunout do shiny a fungovat interaktivně
    - implicitní mohou být předpočítané
    - jiné se pak mohou nastavit až do výše lixelů, které jsou součástí vizualizace´


Pokračovat
----------
- vytvořit a do všech prepar*.R přidat funkci, která zkontroluje, že jsou zadané všechny konfigurační parametry a že mají validní hodnotu
- do konfigurace jména, která řeknou, které sloupce jsou id nehody, ... (p1, ...)
- začít psát dokumentaci
- přidat hlídání chyb a logování
    - do všech funkcí přidat logování
    - při paralelním nutno přidat do každého jádra
        - see: https://github.com/HenrikBengtsson/future/issues/306
- zkontrolovat úpravy ve funkcích pro hotspot a cluster preparation
- do načítání nehod přidat kontroly a ukončit, když chyba


Vizuální pohled na klastry
--------------------------
- podívat se očima na klastry v guts/shiny
    - bez ohledu na název jsou všechny pro stejné období, IMHO 2019--2021
- napsat funkci pro vizualizace ve statické mapě


Předání dat Štěpánovi
---------------------
- tabulka lixels
    - sloupce lixel_id, geometrie, density, klastr_id
    - jen lixely, které jsou součástí nějakého klastru nebo s hustotou v 95. kvantilu a výše
- tabulka accidents
    - sloupce p1 a klastr_id
    - jen nehody, které jsou součástí klastrů
tabulky po bufferovaných okresech
    - otázka, co dělat s okraji: nechat/oříznout
    - pokud oříznout, co klastry na pomezí? asi nechat celé?
každá tabulka je pro jeden okres a jeden čas
    - to znamená, že
        - všechno za tím (klastry) se musí počítat nejen pro okresy, ale i pro časy


Hotspoty/klastry
----------------

- vyzkoušet výpočet NKDE paralelně s neváženými nehodami a vážnými pomocí injuries
- PAI optimalizace parametrizace tvorby klastrů
- jak zahrnout čas? zatím se počítá na všech nehodách. jak to udělat? možnosti:
    - statická tabulka s rozsahy datumů, pro které se to počítá
    - nějaký automat
    - jen poslední klouzavé okno (např. 3 roky zpět od posledního data)
- otázka: optimalizovat parametry klastrů globálně (tj. PAI celku, nebo po jednotlivých klastech)?
    - pokud po klastrech, jak?


Mapy
----

Pro všechny okresy:
- zkontrolovat počet souvislých podgrafů
- spustit kontrolu, o které psal Gelb

Funkce:
- SF silnice v .rds jsou nově sfnetworks -- tomu se bude muset přizpůsobit kód, který na tom staví
- vyřešit spojování blízkých bodů v sfnetworks
    - problém:
        - buď vyhodím nahrazené cesty, ale to vyhodí i všechny smyčky v síti,
        - nebo nevyhodím smyčky, ale zůstanou tam i původní silnice
    - dělá to parametr simplify na řádku
        tidygraph::convert(sfnet, sfnetworks::to_spatial_contracted, cls, cmp,
                           simplify = FALSE)
- zrychlit hledání klastrů hotspotů na sf/sfnetworks/spNetwork
- CRS všude vytahat z funkcí do jejich interface -- tam použít konstatny
- funkce create_sf_nb() používá sf_touches() -- použít raději from -- to v lixelech?

Tvorba OSM
- osmium nechtělo pokračovat, když soubory .osm existují
    - na začátku funkce, která je má vytvořit, je třeba je vymazat
    - zatím jsem to vyřešil pomocí --overwrite


Nehody
------

V současnosti se natahují jen soupce z tabulky nehody a z GPS se doplní souřadnice.
- doplnit ostatní sloupce, které budou potřeba
- vyhodit sloupce, které nejsou potřeba
- jak počítat závažnost nehody?
- create_districts_accidents() běží na málo jádrech, protože  vyžaduje hodně paměti -- asi kvůli kopírování velké tabulky accidents; asi by šlo zlepšit, kdyby se tabulka prvně cropem rozdělila na kusy a ty se poslaly přímo do paralelizace


Všude
-----

- počet workers vzít z get_number_of_workers()
- odstranit jména souborů z tabulky districts a všude, kde se na to odkazuje, a nahradit to funkcemi, které budou používat id z districts
- spojit všechny prepare_*.R do jednoho souboru a přidat logování
- najít všechna volání purrr a paralelizovat, co je možné


Úklid na konec
--------------
- vymazat zakomentované řádky
- vymazat guts/test.R
