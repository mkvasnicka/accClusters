TODO
====

Now
---

- grid_shape v NKDE dořešit s autorem balíku
    - teď to má provizorní řešení -- tinkering s gridem
- PWALK() zůstane někdy (při accidents?) viset -- proč?
    - ukončí otevřené soubory, přejde na 1 jádro, tam běží na 100 %, ale nic se
        neděje (tedy nic očividného)
    - opravil by to schedulling?
    - vyzkoušet na notebooku -- tam se to imho nedělo (je to možné?)
- tvorba profilů
    - vyhodit nepoužívané testovací funkce?
    - vyhodit zakomentovaný kód



Big Picture
-----------
- densities neloguje chyby do souboru (když spadne???)
- fixovat parametry tvorby klastrů -- shiny je musí mít fixní, takže je uživatel
  nemůže měnit
- napsat nápovědu pro parametry tvorby klastrů + profily
- zkontrolovat kód
- napsat dokumentaci
- docker + integrovat detekci paměti + cpu uvnitř dockeru
    - mám kód, ale zatím ho nepoužívám



Parametrizace
-------------

- najít optimální nastavení parametrů
- podívat se, jak se liší klastry pro continuous a discontinuous
- podívat se, co dělá adaptive



Refactoring
-----------

- pročistit kód

- vyhodit:
    - process_command_line_arguments()
    - unit_cost(s)()
    - handle_time_widnow()

- PWALK by mělo throw exception, když selže
    - je potřeba najít všechna místa, kde se používá, a podívat se, jestli jsou v tryCatch()

- rozmyslet, jaké sloupce by měly obsahovat tabulky nehod + ty, které používáme, standardizovat
    - pro případ, že policie sloupce přejmenuje -- není kulturní, abychom používali jejich interní značky
    - nutné domluvit se Štěpánem, co z toho použije
        - data by to mělo chystat i pro něj -- aby se vzala data z guts a šoupla do shiny app

- při exportu do shiny ořezat lixely a klastry na okres
    - lixely nechat jen ty, které jsou uvnitř skutečného okresu
    - klastry nechat celé, které aspoň částí zasahují do okresu

- policajti můžou chtít několik různých vah nehod -- nebo koneckonců jiného nastavení
    - návrh nového řešení -- profily, které se všechny vytvoří
    - nově začíná řešit skript guts/functions_profiles.R
    - moje představa je taková, že uživatel bude mít někde nějaký konfigurační soubor a profily
    - prvně se načte guts_config, pak uživatelská konfigurace a pak profil
        - profil tak může přepsat automatická nastavení
        - profilů může být víc
        - pokud žádný není, vytvoří se profil default
        - nastavení profilů se musí exportovat do shiny souboru
        - asi se musí vyexportovat i zvlášť, aby shiny vědělo, co má tak zhruba k dispozici
    - všechny skripty se musí upravit tak, že se nejdřív vyexportuje seznam profilů, a pak
        všechny skripty vytvoří nejen data pro okres nebo okres x čas, ale místo toho
        okres x profil nebo okres x čas x profil
        - musí se projevit je jménu výstupu
    - co je hotové
        - nástřel načítání a kontroly profilů
        - zatím ale nenačítá ani guts_config, ani uživatelský konfig
    - dodělat
        - načítání guts_config a uživatelský config
        - vlastní zpracování
    - toto by mělo nahradit různé váhy nehod, které jsou v současnosti v kódu + profily
    - PROBLÉM: různé profily se mohou lišit v různých stádiích výpočtu: v tvorbě map
        (délka lixelů etc.), výpočtu hustot (nastavení NKDE), určení klastrů
        - co s tím???



Vizuální pohled na klastry
--------------------------
- podívat se očima na klastry v guts/shiny
    - bez ohledu na název jsou všechny pro stejné období, IMHO 2019--2021
- napsat funkci pro vizualizace ve statické mapě



Hotspoty/klastry
----------------

- vyzkoušet výpočet NKDE paralelně s neváženými nehodami a vážnými pomocí injuries
- PAI optimalizace parametrizace tvorby klastrů
- jak zahrnout čas? zatím se počítá na všech nehodách. jak to udělat? možnosti:
    - statická tabulka s rozsahy datumů, pro které se to počítá
    - nějaký automat
    - jen poslední klouzavé okno (např. 3 roky zpět od posledního data)
- otázka: optimalizovat parametry klastrů globálně (tj. PAI celku, nebo po jednotlivých klastech)?
    - pokud po klastrech, jak?


Mapy
----

Pro všechny okresy:
- zkontrolovat počet souvislých podgrafů
- spustit kontrolu, o které psal Gelb

Funkce:
- SF silnice v .rds jsou nově sfnetworks -- tomu se bude muset přizpůsobit kód, který na tom staví
- vyřešit spojování blízkých bodů v sfnetworks
    - problém:
        - buď vyhodím nahrazené cesty, ale to vyhodí i všechny smyčky v síti,
        - nebo nevyhodím smyčky, ale zůstanou tam i původní silnice
    - dělá to parametr simplify na řádku
        tidygraph::convert(sfnet, sfnetworks::to_spatial_contracted, cls, cmp,
                           simplify = FALSE)
- zrychlit hledání klastrů hotspotů na sf/sfnetworks/spNetwork
- CRS všude vytahat z funkcí do jejich interface -- tam použít konstatny
- funkce create_sf_nb() používá sf_touches() -- použít raději from -- to v lixelech?

Tvorba OSM
- osmium nechtělo pokračovat, když soubory .osm existují
    - na začátku funkce, která je má vytvořit, je třeba je vymazat
    - zatím jsem to vyřešil pomocí --overwrite


Nehody
------

V současnosti se natahují jen soupce z tabulky nehody a z GPS se doplní souřadnice.
- doplnit ostatní sloupce, které budou potřeba
- vyhodit sloupce, které nejsou potřeba
- jak počítat závažnost nehody?
- create_districts_accidents() běží na málo jádrech, protože  vyžaduje hodně paměti -- asi kvůli kopírování velké tabulky accidents; asi by šlo zlepšit, kdyby se tabulka prvně cropem rozdělila na kusy a ty se poslaly přímo do paralelizace


Všude
-----

- počet workers vzít z get_number_of_workers()
- odstranit jména souborů z tabulky districts a všude, kde se na to odkazuje, a nahradit to funkcemi, které budou používat id z districts
- spojit všechny prepare_*.R do jednoho souboru a přidat logování
- najít všechna volání purrr a paralelizovat, co je možné


Úklid na konec
--------------
- vymazat zakomentované řádky
- vymazat guts/test.R
