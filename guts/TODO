TODO
====

Refactoring
-----------
- opravit výpočty s time window -- v jednom běhu ~ efektivnější využití jádra
    - prvně se map() vytvoří víc tabulek tab (pro každý řádek time window 1), pak se spojí a spustí
- guts_config.R bude pevně v jádře
    - parametry, které zadají uživatelé se budou volat v bashi přes --profile
    - přejmenovat --profile na --config
- vytvořit a do všech prepar*.R přidat funkci, která zkontroluje, že jsou zadané všechny konfigurační parametry a že mají validní hodnotu
- do konfigurace jména, která řeknou, které sloupce jsou id nehody, ... (p1, ...)
- začít psát dokumentaci
- time window nebude v samostatném souboru, ale jako tribble() v uživatelském profilu/configu
- přidat hlídání chyb a logování


Pokračovat
----------
- zkontrolovat úpravy ve funkcích pro hotspots preparation
- vytvořit profily -- zatím je jen jeden
- do všech funkcí přidat logování -- při paralelním nutno přidat do každého jádra
    - see: https://github.com/HenrikBengtsson/future/issues/306


Předání dat Štěpánovi
---------------------
- tabulka lixels
    - sloupce lixel_id, geometrie, density, klastr_id
    - jen lixely, které jsou součástí nějakého klastru nebo s hustotou v 95. kvantilu a výše
- tabulka accidents
    - sloupce p1 a klastr_id
    - jen nehody, které jsou součástí klastrů
tabulky po bufferovaných okresech
    - otázka, co dělat s okraji: nechat/oříznout
    - pokud oříznout, co klastry na pomezí? asi nechat celé?
každá tabulka je pro jeden okres a jeden čas
    - to znamená, že
        - všechno za tím (klastry) se musí počítat nejen pro okresy, ale i pro časy


Hotspoty/klastry
----------------

- vyzkoušet výpočet NKDE paralelně s neváženými nehodami a vážnými pomocí injuries
- PAI optimalizace parametrizace tvorby klastrů
- jak zahrnout čas? zatím se počítá na všech nehodách. jak to udělat? možnosti:
    - statická tabulka s rozsahy datumů, pro které se to počítá
    - nějaký automat
    - jen poslední klouzavé okno (např. 3 roky zpět od posledního data)
- otázka: optimalizovat parametry klastrů globálně (tj. PAI celku, nebo po jednotlivých klastech)?
    - pokud po klastrech, jak?


Mapy
----

Pro všechny okresy:
- zkontrolovat počet souvislých podgrafů
- spustit kontrolu, o které psal Gelb

Funkce:
- SF silnice v .rds jsou nově sfnetworks -- tomu se bude muset přizpůsobit kód, který na tom staví
- vyřešit spojování blízkých bodů v sfnetworks
    - problém:
        - buď vyhodím nahrazené cesty, ale to vyhodí i všechny smyčky v síti,
        - nebo nevyhodím smyčky, ale zůstanou tam i původní silnice
    - dělá to parametr simplify na řádku
        tidygraph::convert(sfnet, sfnetworks::to_spatial_contracted, cls, cmp,
                           simplify = FALSE)
- zrychlit hledání klastrů hotspotů na sf/sfnetworks/spNetwork
- CRS všude vytahat z funkcí do jejich interface -- tam použít konstatny
- funkce create_sf_nb() používá sf_touches() -- použít raději from -- to v lixelech?

Tvorba OSM
- osmium nechtělo pokračovat, když soubory .osm existují
    - na začátku funkce, která je má vytvořit, je třeba je vymazat
    - zatím jsem to vyřešil pomocí --overwrite


Nehody
------

V současnosti se natahují jen soupce z tabulky nehody a z GPS se doplní souřadnice.
- doplnit ostatní sloupce, které budou potřeba
- vyhodit sloupce, které nejsou potřeba
- jak počítat závažnost nehody?
- create_districts_accidents() běží na málo jádrech, protože  vyžaduje hodně paměti -- asi kvůli kopírování velké tabulky accidents; asi by šlo zlepšit, kdyby se tabulka prvně cropem rozdělila na kusy a ty se poslaly přímo do paralelizace


Všude
-----

- počet workers vzít z get_number_of_workers()
- odstranit jména souborů z tabulky districts a všude, kde se na to odkazuje, a nahradit to funkcemi, které budou používat id z districts
- spojit všechny prepare_*.R do jednoho souboru a přidat logování
- najít všechna volání purrr a paralelizovat, co je možné


GIS
---
- napsat export klastrů do GISu
