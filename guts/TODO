TODO
====

Refactoring
-----------
- zafixovat adresářovou strukturu tak, aby stačilo zadat začátky cest
    - společný začátek cesty: DIR_ORIGIN
    - alternativní začátky cest: RAW_DATA_DIR, DATA_DIR, OUTPUT_DIR a LOG_DIR
    - hotovo:
        - zrušeny staré konstanty
        - zavedeny nové funkce
    - nutno zkontrolovat

- guts_config.R bude pevně v jádře
    - parametry, které zadají uživatelé se budou volat v bashi přes --profile
    - přejmenovat --profile na --config

- process_command_line_arguments() předpokládá, že profily jsou podadresář guts --
  změnit

- PWALK by mělo throw exception, když selže
    - je potřeba najít všechna místa, kde se používá, a podívat se, jestli jsou v tryCatch()

- rozmyslet, jaké sloupce by měly obsahovat tabulky nehod + ty, které používáme, standardizovat
    - pro případ, že policie sloupce přejmenuje -- není kulturní, abychom používali jejich interní značky
    - nutné domluvit se Štěpánem, co z toho použije
        - data by to mělo chystat i pro něj -- aby se vzala data z guts a šoupla do shiny app

- rozmyslet si, jestli můžeme chtít, aby se uvažovalo víc různých typů nákladů nehod -- teď je to naimplementované částečně a asi nekonzistentně
    - tabulka accidents může mít víc sloupců pro náklady nehody
    - tabulka densities má jen jeden sloupec pro hustotu, která se počítá z nákladů
        - používá se to, co je zadané v NKDE_WEIGHTS (implicitně "accident_cost")
    - tabulka klastrů volá náklady
        - nepřímo přes density -- není jasné, jaké náklady se tu používají
        - přímo přes hodnotu klastru, která se bere z nehod -- současný kód neumožňuje zadat
    - otázka, jak to funguje s profily -- nemění pojmenované profily jména souborů?
        - a pokud ano, funguje to konzistentně?


Pokračovat
----------
- vytvořit a do všech prepar*.R přidat funkci, která zkontroluje, že jsou zadané všechny konfigurační parametry a že mají validní hodnotu
- do konfigurace jména, která řeknou, které sloupce jsou id nehody, ... (p1, ...)
- začít psát dokumentaci
- přidat hlídání chyb a logování
    - do všech funkcí přidat logování
    - při paralelním nutno přidat do každého jádra
        - see: https://github.com/HenrikBengtsson/future/issues/306
- zkontrolovat úpravy ve funkcích pro hotspot a cluster preparation
- do načítání nehod přidat kontroly a ukončit, když chyba


Vizuální pohled na klastry
--------------------------
- podívat se očima na klastry v guts/shiny
    - bez ohledu na název jsou všechny pro stejné období, IMHO 2019--2021
- napsat funkci pro vizualizace ve statické mapě


Předání dat Štěpánovi
---------------------
- tabulka lixels
    - sloupce lixel_id, geometrie, density, klastr_id
    - jen lixely, které jsou součástí nějakého klastru nebo s hustotou v 95. kvantilu a výše
- tabulka accidents
    - sloupce p1 a klastr_id
    - jen nehody, které jsou součástí klastrů
tabulky po bufferovaných okresech
    - otázka, co dělat s okraji: nechat/oříznout
    - pokud oříznout, co klastry na pomezí? asi nechat celé?
každá tabulka je pro jeden okres a jeden čas
    - to znamená, že
        - všechno za tím (klastry) se musí počítat nejen pro okresy, ale i pro časy


Hotspoty/klastry
----------------

- vyzkoušet výpočet NKDE paralelně s neváženými nehodami a vážnými pomocí injuries
- PAI optimalizace parametrizace tvorby klastrů
- jak zahrnout čas? zatím se počítá na všech nehodách. jak to udělat? možnosti:
    - statická tabulka s rozsahy datumů, pro které se to počítá
    - nějaký automat
    - jen poslední klouzavé okno (např. 3 roky zpět od posledního data)
- otázka: optimalizovat parametry klastrů globálně (tj. PAI celku, nebo po jednotlivých klastech)?
    - pokud po klastrech, jak?


Mapy
----

Pro všechny okresy:
- zkontrolovat počet souvislých podgrafů
- spustit kontrolu, o které psal Gelb

Funkce:
- SF silnice v .rds jsou nově sfnetworks -- tomu se bude muset přizpůsobit kód, který na tom staví
- vyřešit spojování blízkých bodů v sfnetworks
    - problém:
        - buď vyhodím nahrazené cesty, ale to vyhodí i všechny smyčky v síti,
        - nebo nevyhodím smyčky, ale zůstanou tam i původní silnice
    - dělá to parametr simplify na řádku
        tidygraph::convert(sfnet, sfnetworks::to_spatial_contracted, cls, cmp,
                           simplify = FALSE)
- zrychlit hledání klastrů hotspotů na sf/sfnetworks/spNetwork
- CRS všude vytahat z funkcí do jejich interface -- tam použít konstatny
- funkce create_sf_nb() používá sf_touches() -- použít raději from -- to v lixelech?

Tvorba OSM
- osmium nechtělo pokračovat, když soubory .osm existují
    - na začátku funkce, která je má vytvořit, je třeba je vymazat
    - zatím jsem to vyřešil pomocí --overwrite


Nehody
------

V současnosti se natahují jen soupce z tabulky nehody a z GPS se doplní souřadnice.
- doplnit ostatní sloupce, které budou potřeba
- vyhodit sloupce, které nejsou potřeba
- jak počítat závažnost nehody?
- create_districts_accidents() běží na málo jádrech, protože  vyžaduje hodně paměti -- asi kvůli kopírování velké tabulky accidents; asi by šlo zlepšit, kdyby se tabulka prvně cropem rozdělila na kusy a ty se poslaly přímo do paralelizace


Všude
-----

- počet workers vzít z get_number_of_workers()
- odstranit jména souborů z tabulky districts a všude, kde se na to odkazuje, a nahradit to funkcemi, které budou používat id z districts
- spojit všechny prepare_*.R do jednoho souboru a přidat logování
- najít všechna volání purrr a paralelizovat, co je možné


Úklid na konec
--------------
- vymazat zakomentované řádky
- vymazat guts/test.R
