---
title: "Method for Traffic Accidents Hotspot Detection"
output:
  pdf_document: default
  html_document: default
papersize: a4
fontsize: 10pt
margins: 2cm
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## KDE

### ArcGIS Pro: How Kernel Density works

source: <https://pro.arcgis.com/en/pro-app/latest/tool-reference/spatial-analyst/how-kernel-density-works.htm>

ArcGIS to umí spočítat pro body i pro lines. The **population** field can be used to weight some features more heavily than others or allow one point to represent several observations. For example, one address might represent a condominium with six units, or some crimes might be weighted more heavily than others in determining overall crime levels.

For points, it's calculated on raster cells. The volume under the surface equals the Population field value (1 if none is specified). If a population field setting other than NONE is used, each item's value determines the number of times to count the point. For example, a value of 3 will cause the point to be counted as three points. The values can be integer or floating point. Uses quartic kernels.

For lines, see the web. It's not network KDE. It's still a raster but the density is highest on the line and diminishing with the distance from the line.

Density is calculated as

$$
\textrm{density} = \frac{1}{\textrm{radius}^2}
    \sum_{i=1}^n \left[\frac{3}{\pi}\cdot \textrm{pop}_i 
        \left(1 - \left(\frac{\textrm{dist}_i}{\textrm{radius}}\right)^2\right)^2\right],
    \quad\textrm{for }\textrm{dist}_i < \textrm{radius},
$$

where $i$ is the index of points, $\textrm{pop}_i$ is the population field value of point $i$, and $\textrm{dist}_i$ is the distance between the point $i$ and the location. It is then multiplied by the number of points or sum of the population field to make the spatial integral equal to the number of points or the sum of the population field rather than being equal to 1.

Default search radius (bandwidth) is set as follows (Silverman's Rule-of-thumb bandwidth):

1.  Calculate the mean center of input points (weighted by population).
2.  Calculate the distance from the (weighted) mean center for all points.
3.  Calculate the (weighed) median of these distances, $D_m$.
4.  Calculate the (weighed) standard distance, $SD$.
5.  Calculate $\textrm{SearchRadius} = 0.9 \cdot \min\left(SD, \sqrt{\frac{1}{\ln(2)}}\cdot D_m\right) \cdot n^{-0.2},$ where $n$ is the number of points or the sum of the population field value (if supplied).
    -   The unweighted distance is $SD = \sqrt{\frac{\sum_{i=1}^n (x_i - \bar{X})^2}{n} + \frac{\sum_{i=1}^n (y_i - \bar{Y})^2}{n} + \frac{\sum_{i=1}^n (z_i - \bar{Z})^2}{n}}$, where $x_i$, $y_i$, and $z_i$ are the coordinates for feature $i$, $\{\bar{X}, \bar{Y}, \bar{Z}\}$ represents the mean center, and $n$ is the number of the features.

    -   The weighted distance is $SD = \sqrt{\frac{\sum_{i=1}^n w_i(x_i - \bar{X}_w)^2}{\sum_{i=1}^n w_i} + \frac{\sum_{i=1}^n w_i(y_i - \bar{Y_w})^2}{\sum_{i=1}^n w_i} + \frac{\sum_{i=1}^n w_i(z_i - \bar{Z}_w)^2}{\sum_{i=1}^n w_i}}$, where $w_i$ is the weight at feature $i$ and $z_i$ are the coordinates for feature \$i\$ and $\{\bar{X}_w, \bar{Y}_w, \bar{Z}_w\}$ represents the weighted mean center.

Umí to použít bariéry, které prodlouží vzdálenost mezi buňkami, nebo zablokují cestu. Např. může být ohraničení silnice zleva a zprava. Pak KDE nehod zůstanou vpodstatě jen na silnici. Dokumentace neříká, jak se počítá. Jen: The tool provides a much better estimation of density using the barrier, where the distance is measured along with the road network, than using the shortest distance between the accident locations.

### McSwiggan--Baddeley--Nair: Kernel Density Estimation on a Linear Network, 2016

They develop a numerical method to calculate Kernel Density Estimates on a linear network that have the density that integrates correctly to unity. The estimation is based on a heat distribution. They claim that their algorithm is must faster than its alternatives. In particular, it is only quadratic in bandwidth (the others are exponential). It uses "equal-split continuous" method to distribute the densities across crossroads.

They divide each line segment into equal sub-segments of length at most $\Delta x$: A line segment of length $l = m \Delta x + s$, where $m$ is an integer and $0 \geq s < \Delta x$, is divided into $m+1$ segments of equal length $r = l/(m+1)$. The elements are then treated as of equal length $\Delta x$.

The endpoints of the line elements are called nodes $z_j$, $j=1,\ldots,J$. Each state of the algorithm is a vector of real values $\lambda_j$ for each node $z_j$. The initial state of the algorithm is: All values $\lambda_j$ are initialized to 0. For each data point $x_i$, the line element $[z_j,z_{j'}]$ containing $x_i$ is identified; then $x_i$ is represented as a convex combination $x_i = p z_j + (1-p) z_{j'}$ of the endpoints; the values $\lambda_j$ and $\lambda_{j'}$ are incremented by the weights $p$ and $1-p$, respectively.

$f_t(u)$ denotes the solution of the time-dependent heat equation on linear network. It is incremented:

$$
f_j^{k+1} = \alpha\sum_{j' \sim j} f_{j'}^k + (1 - \alpha\textrm{deg}(z_j)f_j^k),
$$

where $k$ is the counter, $j' \sim j$ means that nodes $z_j$ and $z_{j'}$ are joined by a line element, $\textrm{deg}(z_j)$ is the degree of node $z_j$ in the discretized network, and $\alpha = \beta \Delta t / (\Delta x)^2$ with $\beta = 1/2$.

In matrix form: $f^{k+1} = A f^k$ where $f^k = (f_1^k, \ldots, f_J^k)$ and $A = I + \alpha M$, where $I$ is the identity matrix and $M$ is the centered incidence matrix with off-diagonal entries $m_{j,j'} = 1$ if $j \sim j'$ and $m_{j,j'}=0$ otherwise, and diagonal entries $m_{j,j} = -\sum_{j'} m_{j,j'} = \textrm{deg}(z_j)$. The matrix $A$ is extremely sparse: most nodes have degree 2 so that most rows have only three non-zero entries. In **spatstat**, the matrix $A$ is implemented as a sparse matrix using the **Matrix** package.

$B = \max\{\textrm{deg}(z_j) + \textrm{deg}(z_{j'}): \quad j \sim j'\}$

time increment: $\Delta t < (\Delta x)^2 / (\beta B) = 2(\Delta x)^2/B$ and $\Delta t \leq \sigma\Delta x / 3$

number of iterations: $N = \sigma^2 / \Delta t$ \~ počet iterací (a tedy délka výpočtu) roste s bandwidth $\sigma$ (minimálně kvadraticky, možná nepřímo i přes $\Delta t$) a délkou lixelu $\Delta x$ (kratší lixely znamenají taky rychlejší inicializaci výpočtu a menší potřebnou paměť)

In their application they set: bandwidth \$\\sigma = \$ 1000 m, length of lixel \$\\Delta x = \$ 50 m, the maximum permissible value of $\Delta t = 50^2/(9/2) = 554$, while the propagation constrain imposes $\Delta t \leq \sigma\Delta x / 3 = 16.7\sigma$.

V paperu nijak neřeší to, že by body mohly mít nějakou přidělenou hodnotu (jako je population v ArcGISu). Zkontrolovat, jak je to v balíku spatstat.

### balík spatstat

funkce density() -- generická; density.lpp() -- to, co chceme; má parametr weight, který dává váhu jednotlivým bodům -- prostě váhy v pořadí bodů v objektu; dělá to přesně totéž, jako, když se tam nasype těch puntíků víc; ovšem váhy mohou být kladné, záporné i nulové; když je to implementované, asi je to ok

```{r, eval=FALSE}
library(spatstat)
X <- runiflpp(3, simplenet)
DX <- density(X, 0.2, weights = c(1,5,20), verbose=FALSE)
Y <- X
Y$data <- Y$data[rep(1:3, c(1,5,20)), ]
DY <- density(Y, 0.2, verbose = FALSE)
identical(DX, DY)
plot(DX, style = "w")
plot(DY, style = "w")
```

### Okabe et al.: A kernel density estimation method for networks, its computational method and a GIS-based tool, 2009

Druhý paper, který odvozuje NKDE. Na rozdíl od prvního (Xie) řeší žádoucí vlastnosti a unbiasedness. Odkazuje na paper, že prosté použití KDE na síti je biased a zavádí dvě unbiased možnosti: equal-split kernel functions a equal-split continuous kernel functions. Ty spojité nemají zuby (na skutečné síti nemusí nespojitá verze vypadat až tak divně), ale je to výpočetně mnohem pomalejší. Navíc nesplňuje dvě žádoucí vlastnosti, které nespojitá verze splňuje. Proto doporučují používat tu nespojitou. (Mají šest žádoucích vlastností, ale nenašli funcki, která jich splňuje všech šest -- jen pět: ta nespojitá equal-split.)

Ukazují na příkladu nehod na síti -- na ulicích japonského města (2190 km), nehody za rok 2004. Doporučený bandwidth je prý 100--300 m -- oni používají 200 m.

O lixelech nemluví, jak moc špatné jsou různé nehody, neřeší.

### Loo--Yao--Wu: Spatial Point Analysis of Road Crashes in Shanghai: A GIS-based Network Kernel Density Method, 2011

Používají Network Kernel Density pro nalezení hotspotů nehod. Nehody nijak neváží.

Rozdělení silnic na lixely má dvě nevýhody: 1) obecně neplatí, že lixely jsou stejně dlouhé (je tam hodně krátkých) a 2) nehoda je přilepená na silnici k nejbližšímu referenčnímu bodu. Řeší to tím, že použíjí "dissolving procedure", která zřejmě slepí krátké úseky silnice dohromady. Neříkají, jak to přesně dělají.

Zajímají se o dva typy nehod (auto--chodec a auto--auto) a to, jak se liší jejich umístnění v prostoru. Na to mají metriku $r(i) = \log\frac{f_{vp}(i) + \sigma}{f_{vv}(i) + \sigma},$ kde $f_{vp}(i)$ je hustota nehod chodců s auty, $f_vv(i)$ hustota nehod aut s auty a $\sigma=0.000001$ je konstanta.

Lixely mají délu 100 m. Bandwidth zkoušeli 100 m, 250 m, 500 m a 1000 m; tvrdí, že ty kratší (do 250 m) díl lokalizují hotspoty -- pro delší se moc slívají. Používaji quartic kernel.

### Harirforoush--Bellalite: A new integrated GIS-base analysis to detect hotspots: A case study of the city of Sherbrook, 2019

Hledají hotspoty v několika krocích:

1.  použijí NKDE na každý rok zvlášť; lixely mají 10 m, optimální bandwidth hledají iterativně; zkouší od 50 do 500 m po 50 m a vybrali 100 m
2.  hotspot je to, kde v každém ze tří roků je hustota vyšší než 3 směrodatné odchylky od průměru -- tomu říkají "potential hotspot"
3.  rozdělí hotspoty do kategorií: průběžné silnice, křižovatky se třemi nožičkami, čtyřmi nožičkami, ...; na každém potenciálním hotspotu určitého typu (a všech místech tohoto typu) spočítali podíl nehod a počtu aut, co tam projedou; mají nějaké kritické hodnoty této statistiky
4.  hotspot je potenciální hotspot se statisticky významným počtem nehod vůči průjezdu aut (při kontrole o typ křižovatky, ...); navíc to umožňuje seřadit od nejhorší po nejmíň hrozný hotstpot.

Závažnost nehod neřeší -- jen jejich počet a zda je významný vzhledem k průjezdu aut.

### Briz-Redón et al.: Identification of differential risk hotspots for collision and vehicle type in directed linear network, 2019

Cíl je najít místa, kde je nějaký typ dopravní nehody výrazně četnější (vzhledem k počtu dopravních nehod jako takových). Type myslí zeména typ vozidla. Data za vnitřní město Valencie za 3 roky.

Zjednodušili silniční síť (balík **SpNetPrep**): spojili úseky, které měly jen průběžné body, zjednodušili křižovatky a kruháče.

Použili NKDE McSwiggana z balíku **spatstat**. Bandwidth hledali v rozsahu 50--150 m, použili 100 m. Lixely měli délky 50 m. K tomu balík **DRHotNet**.

Hotspoty našli takto: vybrali lixely, které měly NKDE vyšší než průměr plus $k\times$ směrodatnou odchylku. Pak vybrali jen ty, které měli v dosahu bandwidth $\sigma$ aspoň $n$ nehod (tj. fakticky rozšířili o lixely do vzdálenosti $\sigma$). Z nich sestavili hotspoty. Používají $k=1$, ale tvrdí, že ideální je $k=1.5$; $n$ používají 40 nebo 45. Rozšíření hotspotů o $\sigma$ vysvětlují tak, že tam vznikají situace, kdy je významný jen jeden lixel, který neobsahuje žádné nebo jen málo nehod. Dívají se na to tak, že lixel je střed lineárního rádiu o délce 100 m po síti (ale jinde mluví o délce 75 m). (Moran I se na lixelech se podle nich nehodí.)

Parametry $k$ a $n$ hledali pokusně pomocí *prediction accuracy index* (PAI) odvozený Chainey et al. (2008), který si upravili. Jejich verze:

$$
\textrm{PAI}_{\textrm{type}} = \frac{n_{\textrm{type}} / N_{\textrm{type}}}{m / M}.
$$

NKDE nedává statistickou významnost. K tomu používají Monte Carlo simulaci ala Bíl et al. (2013): body na silnicích jsou fixní, ale mění jim typ nehody. Dělají 750 simulací (citují paper, že je to dost) a spočítají $p$-hodnotu.

### Briz-Redón et al.:Spatial analysis of traffic accidents near an between road intersections in a directed linear network, 2019

Cíl je modelovat počet nehod ve vnitřní čtvrti Valencie pomocí Bayesovského modelu. K tomu rozdělí silnice nakřižovatky (20 m od křižovatky) a vnitřní silnice. Kódují tam hromadu věcí (pruh pro busy, semafory, ... a čtyři typy silnic získané klastrováním délky, počtu příchozích a výchozích ulic a jejich úhlů). Jako kontrolu dělaují NKDE podle McSwiggana.

Silnice zjednodušili pomocí **SpNetPrep**. Bandwidth nastavili na 100 m. Tvrdí, že McSwiggan trochu řeší edge effect. Pomocí NKDE hledají hotspots a coldspots. Dělají to tak, že na NKDE na lixelech spočítají local Moran's I a vezmou hodnoty statisticky významné na 10 % a souvisle je sgrupují. Nakonec spočítají "basic average intensity of the point pattern (number of events per unit lenght) in each of the zones of intereset" a porovnají s přímými sousedy, což jim umožní říct, co je hot- a co cold-spot. Ty pak porovnávají s bayesiánským modelem.

### Thakali, Kwon a Fu: Identification of crash hotspots using kernel density estimation and krigin methods: a comparison, 2015

Porovnává hledání hotspotů pomocí KDE a kriging. Tvrdí, že kriging je lepší. Ale oboje dělají v prostoru, ne na silnici, přesněji, okolo silnic nakreslí buffer 400 m na každou stranu a dělají to na pixlech o straně 400 m v tom bufferu. U KDE zkouší bandwidth 400 a 800 m. Hotspot definují jako horní decil hodnoty KDE. Kriging a KDE porovnávají podle PAI, kde

$$
\textrm{PAI} = \frac{n/N}{m/M},
$$

kde $n$ je počet nehod v hotspotech, $N$ je počet všech nehod, $m$ je celková délka / plocha všech hotspotů a $M$ je celková délka / plocha všech silnic.

Data jsou nehody na dálnicích (tj. velmi malá sít, se kterou navíc zachází jako s plochou) v jedné county v Minnesotě, která obsahuje Minneapolis.

### Mohaymany, Shahri a Mirbagheri: GIS-based method for detecting high-crash-risk road segments using network kernel density estimation, 2013

Odhadují NKDE na 60 km dlouhé venkovské cestě (asi v Indii). Mají tři roky a pro každý to odhadují zvlášť. Výsledné NKDE je mezi roky silně korelované (0.8-0.9). Používají ArcGis a SANET.

Bandwidth NKDE používají 1 km. NKDE podle Okabe. Mají významná místa (neměří stat. významnost NKDE, jen nějaké prahy), přestože globální Moran's I je malé, statisticky nevýznamné a mezi roky střídá znaménka.

### Xie--Yan: Kernel Density Estimation of traffic accidents in a network space, 2008

Zřejmě paper, který vymyslel původní network KDE a zavedl pojem *lixel*. Naimplementovali to v ArcGis a SANET. Popisují původní algoritmus (který neřeší rozlívání po silnicích, ale zároveň dobře zvládá různé délky lixelů), testují ho na dopravních nehodách a zkouší, jak moc záleží na typu kernelu, délce lixelu a bandwidth.

Zkouší (ne všechny kombinace) guassovský a quartic kernel, search bandwidth 20, 100, 250, 500, 1000 a 2000 m a délku lixelu 5, 10, 50 a 100 m. Výsledky:

1.  Na typu kernelu nezáleží -- dávají různé hodnoty NKDE, ale relativní výšky jsou pro různé kernely stejné.
2.  Délka lixelu (stejn jako velikost buňky rasteru v planární KDE) ovlivňuje detaily. "the density values along roads lose local variation as lixel length increases. The larger lixel lengths effectively hide the detailed structures shown at finer resolutions." Rozsah, ve kterém NKDE hustoty leží ale na délce lixelu vpodstatě nezávisí.
3.  "Search bandwidth plays the most significant role in structuring the network density pattern. ... the density pattern gets smoother with increasing search bandwidth... The density values are almost invariant with a 500-m search bandwidth, whereas the density variation pattern is quite bumpy with a 20-m bandwidth."

Ideální délka lixelu i bandwidth záleží na aplikaci. Doporučují "to use a set of search bandwidths to reveal 'hot spots' from very local effects to global scale."

Podobně "Because no statistical significance is employed in the process, it is ad hoc and there is no indication of a density threshold above which 'hot spots' can be confidently declared. Experiments with different density thresholds may be needed in real applications."

Taky říkají, že to teď neřeší to, jak vypadají silnice, kolik tam jezdí aut, ..., ani typ nehod. Prý kvůli tomu, že to nemají v datech.

### Kuo, Zeng a Lord: Guidelines for choosing hot-spot analysis tools based on data characteristics, network restrictions, and time distributions, 2011

Srovnání planárního Getis-Ord Gi\* a KDE a síťového Getis-Ord Gi\* a NKDE. Síťové NKDE je zřejmě via Xie--Yan SANET software. Data je "service area of the College Station Police Department (snad u Texas A&M) za leden 2005 až září 2010; mají čtyři typy zločinu a nerozlišené nehody. Neřeší velikost škody. Paper nepsali geostatistici, ale "traffic engineers to solve real-life traffic problems".

Časové rozdíly řeší tak, že data rozdělí do dvou částí (den/noc, pracovní den/víkend), spočítají statistiky a vedle sebe plácnou odpovídající mapy (říkají tomu co-map).

Jejich závěry:

1.  Ve výškově plochých oblastech není třeba síťová KDE, ale stačí planární. (Ale nevím, jak to plyne z jejich analýzy.)
2.  Na rozdíl od KDE Gi\* dává "poor visual effects and cannot provide a clear boundary of risk".
3.  "The Gi\* may have different definitions of the term "hot-spots" from those used by traffic safety professionals. Hot-spots in Gi\* is defined as a point or area where incidents are clustered together by high values, but this is not necessarily a condition affecting traffic safety." (U nich to však může být dané tím, že agregují body nehod do jenoho planárního pixelu. Pak pixel s mnoha a s málo nehodami vede v Gi\* na hodnoty kolem nuly -- podobně, jako když se počítá přímo s body, ale hodnoty jsou výše škody.)
4.  "The hot-spot results from using Gi\* might be different, depending on the scale, location and aggregation units."
5.  "The Gi\* might have an unreliable Z-value for small or spread out data sets because of the limitations that come with a fixed distance band. A distance band should be large enough to ensure that all features have at least one neighbor, but the band should also not be so large that it lets in too many features. Also, for skewed data, the distance band should be large enough to ensure that several neighbors (for the best results, approximately eight) are included for each feature. In rural areas, crash rates tend to be very low (skewed right) and the locations are usually widely spread out. Hence, if one uses the Gi\* under these circumstances, the user is likely to receive a biased Z-value."
6.  Hotspoty z KDE nemají statistickou významnost a různé velikosti buňky vedou na různé výsledky.
7.  Co-mapy umožňují zobrazit víc věcí.
8.  "This study recommends using KDE or 3D KDE maps to present spatial data instead of a Gi\* map." (Ale v úvodu a závěru tvrdí, že se Gi\* a KDE mají používat společně.)

### Srikanth--Srikanth: A Case Study on Kernel Density Estimation and Hotspot Analysis Methods in Traffic Safety Management, 2020

Tvrdí, že odhadnou hotspoty nehod pomocí KDE a jejich statistickou významnost následně pomocí Getis-Ord Gi\*. Ale používají KDE v rovině (ne po silniční síti) -- používají grid po 100 m a různé bandwidth: 250, 500, 750 a 1000 m. Vizuálně vybírají bandwidth 500 m, protože "outperformed other bandwidths in terms of visual clarity".

Následně dělají Getis-Ord Gi\*. Používají "fixed distance band" o délce 5404 stop. Jeho délku hledají tak, aby maximalizoval Global Moran's I. Není jasné, na čem to počítají, ale zdá se, že to počítají přímo na těch nehodách (bodech), ne na KDE. Není mi jasné, v jakém smyslu by to ukazovalo stat. významnost KDE.

Nijak nezohledňují závažnost nehod.

Data: 5 let nehod 2008--2012 v Des Moines, hlavní město Ioway, USA. SW je ArcGIS.

### Hashimoto et al.: Development and application of traffic accident density estimation models using kernel density estimation, 2016

V Japonsku jsou data o nehodách často nedostupná. Článek vyvinul metodu, jak odhadnout, kde jsou nehody, když nemají data. Postup je ten, že rozdělí město mřížkou 250 m a na této mřížce 1) odhadnou planární KDE (ne po silnici) podle počtu nehod (ne jejich závažnosti) a 2) spočítají počet nehod v buňkách mřížky. Tyto hodnoty pak regresují (negativní binomická regrese) na různé věci (délka silnic v buňce, ...). Pomocí toho pak mohou předpovědět hustotu/počet nehod v jiném městě, kde znají hodnoty těch covariates, ale ne počet nehod. Na příkladu dvou měst (na jednom odhadnou, na druhém předpoví) ukazují, že to funguje docela dobře (Spearman rank correlation typicky mezi 0.6 a 0.7, pro nehody s chodci kolem 0.4); KDE funguje nepatrně líp než raw count nehod.

### Yu et al.: Comparative analysis of the spatial analysis methods for hotspot identification, 2014

Pomocí tří kritérií srovnává několik metod hledání problémových úseků silnic (= s mnoha nehodami). Srovnává 1) crash frequency method (silnice se rozdělí na úseky a na každém se spočítá počet nehod), 2) crash rate method (totéž, ale dělí se objemem dopravy), 3) Empirical Bayes method, 4) local spatial autocorrelation method (local Moran's I) a 5) KDE (není jasné, jestli planární, nebo po silnici -- cituje jak planární paper, tak raný paper po silnici: Xie a Yan, 2008); má tu i nějaký algoritimus pro výběr bandwidth.

Data jsou 622 km dlouhý úsek dálnice A1 v UK. Dta mají za 10 let (2001--2010), 7930 nehod.

Většinou vychází, že nejlepší je empirical Bayes (EB) těsně následovaný KDE. KDE je však míň náročná na data a na kvalitu "safety performance function", což je funkce, která se v EB odhaduje a může mít řadu tvarů; navíc zahrnuje i "average annual daily trafic of each road segment", což člověk nemusí mít. Navíc je KDE zjednodušená verze EB. Proto může být prakticky nejlepší.

### Erdogan et al.: Geographical information systems aided traffic accident analysis system case study: city of Afyonkarahisar, 2008

Hledání hotspotů nehod dvěma metodami: 1) repeatability analysis (silnice se rozdělí na úseky po 1 km, na každém spočítá počet nehod a na tom se seběhne odhad Poissona; hotspot má víc než očekávané množství nehod) a 2) KDE (planární, ne po silnici). KDE rozdělili do úrovní: spočítali průměrné KDE tam, kde nebylo nulové, a pak řezali: 0--průměr, průměr--$2\times$průměr, ..., víc než $5\times$průměr. Závažnost nehod neřešili.

Obě metody daly podobné výsledky, jen KDE trochu míň hotspotů.

Data: 400 km dálnic v tureckém regionu. Nehody za 10 let.

### Ivan a Tesla: ROAD AND INTERSECTION ACCIDENTS: LOCALIZATION OF BLACK SPOTS IN OSTRAVA, 2015

Chaoticky napsaný článek, kde dělají několik věcí (na českých datech za roky 2009--2013):

1) Vezmou jen dálnice, silnice pro motorová vozidla a silnice 1.--3. třídy v celé ČR. Rozdělí sinice a křižovatky (50 m od kraje křižovatky), silnice rozdělí na segmenty (to berou od Ředitelství silnic a dálnic). Spočítali počet nehod na 1 km na jednotlivých segmentech silnic a podle toho je setřídili. Nejvíc problematické segmenty byly na D1 a R1 (okolo Prahy). Všechno segmenty s velkým objemem dopravy. (Křižovatky asi neřešili.)

2) Vzali všechny silnice v Ostravě. Na tom spočítali NKDE (podle Okabe et al. 2009). Tady nevyhazovali křižovatky. Měli lixely o délce 20 m a bandwidth 200 m. Jen vykreslili obrázky, včetně 3D.

3) "One of the tools working with distances between accidents, which is suitable for determining whether the traffic accidents cluster and if so at what distance, is Global Auto Nearest Neighbor Distance Method." Asi počítá, kolik bodů mají body ve svém okolí s rostoucí dojezdovou vzdáleností okolí. Když křivka roste prudce, znamená to to spatial clustering, když pomalu, tak rovnoměrné rozdělení bodů na síti. K tomu udělali 300x Monte Carlo simulaci, jak by to mělo vypadat. Tam, kde se očekávaná hodnota proťala se skutečnou křivkou, odhadli "Accidents show a significantly shorter distance between the nearest neighbours and produce statistically significant clusters up to a distance of 30 m.", kde těch 30 m je to, kde se skutečná a očekávaná křivka proťaly. Nezdá se ale, že by s tím pak dál něco dělali.

4) Řešili křižovatky, ale jen mezi silnicemi vyšších tříd v Ostravě. Kruháč chápali jako jednu křižovatku a spojili i několik blízkých křižovatek -- pomocí bufferu 270 m. Celkem měli 118 křižovatek. Na každé spočítali počet nehod a podle toho je setřídili.

5) Standardizovali počet nehod na den, kilometr a 1 000 projetých aut. K tomu použili data o průjezdu aut z cenzu 2010. Tato data ale mají jen pro dálnice a vybrané silnice ve městech. Udělali to v Ostravě. Výsledek je zase jen mapa.

Nikde neřešili závažnost nehod.

### Bíl et al.: Identification of hazardous road locations of traffic accidents by means of kernel density estimation and cluster significance evaluation, 2013

Návrh metody testování statistické významnosti a "stability" klastrů nehod. Ale použití Monte Carlo metody k testování významnosti už udělalo pár lidí před nimi.

Data: 4 roky (2007--2010) nehod v jihomoravském kraji. Ale: berou jen silnice první třídy mimo dálnic a mimo měst. Tyto silnice rozdělí na úseky mezi křižovatkami a pracují s těmito úseky. KDE počítají na těchto úsecích jako úsečkách (na každém zvlášť, tj. není to ani síťové, ani planární, ale one-dimensional KDE). Důvod je ten, že podle nich je třeba brát v úvahu, kolik aut tam projede. Když řeší každý úsek zvlášť, tak se tomu mohou vyhnout. Používají Epanechnikov kernel a bandwidth 100 m. (Proto vyhodili všechny úseky kratší než 200 m.) Počítají přesně, tj. ne na lixelech (aspoň o lixelech nemluví.)

Testování statistické významnosti: Pro každý úsek zvlášť 400x Monte Carlo přehážou počet nehod a umístí je náhodně na úseku. Pak najdou 95% kvantil hodnot KDE, to zprůměrují a řeknou, že to je mez, nad kterou je to stat. významné.

Síla klastru: výška křivky na stat. významnou úrovní děleno celková výška křivky. Čím vyšší, tím je klastr významnější. Závisí na počtu nehod v klastru, délce klastru, počtu nehod na segmentu a délce segmentu. Proto stat. významnou úroveň nastavili tak, aby byla minimálně výška jednoho klobouku rozdělení.

"Stabilita klastru": Policii ve skutečnosti nezajímá stat. významnost, ale počet nehod (s. 269). Řeší to tak, že spočítají hodnotu síly klastru v pěti situacích: jak je, když přidají 1 nebo 2 nehody a když uberou 1 nebo 2 nehody (neříkají, v jaké pozici). Z toho spočítají směrodatnou odchylku a chtějí, aby byla menší než 0.065.

Nikde neřešili závažnost nehod.

## Getis--Ord a local Moran's I

### Getis--Ord: The Analysis of Spatial Association by Use of Distance Statistics, 1992

The first paper defining Getis-Ord $G_i$. "The statistic measures the degree of association that results from the concentration of weighted points (or area represented by a weighted point) and all other weighted points included within a radius of distance $d$ from the original weighted point." The statistic is

$$
G_i(d) = \frac{\sum_{j=1}^n w_{ij}(d) x_j}{\sum_{j=1}^n x_j}, \quad j \textrm{ non equal to } i,
$$

where $\{w_{ij}\}$ is a symmetric one/zero spatial weight matrix with ones for all links defined as being within distance $d$ of a given $i$; all other links are zero including the link of point $i$ itself. Each $i$ has associated a value $x$ (a weight). The variable has a natural origin and is *positive*. The numerator is the sum of all $x_j$ within $d$ of $i$ but not including $x_i$. The denominator is the sum of all $x_j$ not including $x_i$.

They base their argument of random permutations of all observations. Under this assumption, they calculate the expected value $E(G_i)$ and variance $Var(G_i)$. They claim that the permutation distribution of $G_i$ under $H_0$ approaches normality as $n \rightarrow \infty$. When $d$ is small or large enough to encompass the whole area, normality is lost. Tho conditions must be satisfied separately for each point if its $G_i$ is to be assessed via the normal approximation.

In similar way, they define $G_i^*(d)$, which measure association in cases where the $j$ equal to $i$ term is included in the statistic.

The statistic is intended for use only for those variables that posses a natural origin. Thus $Y_i = b X_i$ gives the same results are $X_i$, but $Y_i = a + b X_i$ or $Y_i = \log X_i$ do not.

For significance testing they use $Z_i = \{G_i(d) - E[G_i(d)]\}/\sqrt{Var(G_i(d)}$. A large positive $Z_i$ implies that large values of $x_i$ (values above the mean $x_i$) are within $d$ of point $i$. A large negative $Z_i$ means that small values of $x_i$ are within $d$ of point $i$.

They define also global statistic $G(d)$.

Table 2 gives some idea of the values of standard normal variates for $G(d)$ ($Z(G)$) and $I(d)$ ($Z(I)$). This is for the global measures the same holds but I think the same holds true for their local counterparts too:

| Situation | $Z(G)$ | $Z(I)$ |
|-----------|--------|--------|
| HH        | + +    | + +    |
| HM        | \+     | \+     |
| MM        | 0      | 0      |
| Random    | 0      | 0      |
| HL        | \-     | - -    |
| ML        | - #    | \-     |
| LL        | - -    | + +    |

: Table 2

Legend: HH ... high values within $d$ of other high values; M ... moderate values; L ... low values; Random ... no discernible pattern; + + ... strong positive association (high positive Z scores); + ... moderate positive association; 0 ... no association; \# ... this combination tends to be more negative than HL.

The $I(d)$ statistic has its peculiar weakness in not being able to discriminate between patterns that have high values or low values. Both statistics have difficulty discerning a random pattern from one in which there is little deviaiton from the mean.

The use examples of rate of sudden infant death syndrome (count per 1000 births) and mean price of housing units. The feature used is area given as polygon simplified as a center.

They claim that both global $G(d)$ and $I(d)$ are misleading---there can be no association globally but there can be hotspots locally.

### Ord--Getis: Local Spatial Autorcorrlation Statistics: Distributional Issues and an Application, 1995

They enhance the statistic from their 1992 paper. "In this paper, the statistics $G_i$ and $G_i^*$ are extended to include variables that do not have a natural origin. The cost of this move is that the statistics lose some intuitive appeal, but the benefit is that the earlier restriction no longer applies. In addition, the statistics may incorporate nonbinary weight matrices."

"We now redefine $G_i$ as a standard variate by taking the statistic minus its expectation, $E[G_i]=W_i/(n-1)$, divided by the square root of its variance; at the same time we allow the weight to be nonbinary. The resulting measures are"

$$
\begin{aligned}
G_i(d) &= \frac{\sum_j w_{ij}(d) x_j - W_i \bar x(i)}
    {s(i)\{[(n-1)S_{1i} -W_i^2]/(n-2)\}^{1/2}},
    \quad j \neq i,\\
G_i^*(d) &= \frac{\sum_j w_{ij}(d) x_j - W_i^* \bar x(i)}
    {s(i)\{[n S_{1i}^* -W_i^2]/(n-1)\}^{1/2}},
    \quad \textrm{all }j.\\ 
\end{aligned}
$$

Properties:

1.  When the underlying distribution is normal, so is that of the test statistics (an exact result).
2.  When the underlying distribution is markedly skew, the distribution of the test statistics is no-normal, but approaches normality as the distance is increased.
3.  The statistics for edge cells approach normality more slowly because they have fewer neighbors; the convergence for corner cells is still slower.

The $G_i$ and $G_i^*$ values for various locations on the same map are not independent, especially if the locations are within distance $d$ of one another.

They use example of (cumulative) incidence of AIDS cases per 100,000 population.

### ArcMap: How Hot Spot Analysis (Getis-Ord Gi\*) works

source: <https://desktop.arcgis.com/en/arcmap/latest/tools/spatial-statistics-toolbox/h-how-hot-spot-analysis-getis-ord-gi-spatial-stati.htm>

A tool in ArcGis (in Euclidean space?). To be a statistically significant hot spot, a feature will have a high value and be surrounded by other features with high values as well. The local sum for a feature and its neighbors is compared proportionally to the sum of all features; when the local sum is very different from the expected local sum, and when that difference is too large to be the result of random chance, a statistically significant z-score results.

Calculation:

$$
G_i^* = \frac{\sum_{j=1}^n w_{i,j} x_j - \bar X \sum_{j=1}^n w_{i,j}}
    {S\sqrt{\frac{n\sum_{j=1}^n w_{i,j}^2 - \left(\sum_{j=1}^n w_{i,j}\right)^2}{n-1}}},
$$

where $x_j$ is the attribute value for feature $j$, $w_{i,j}$ is the spatial weight between feature $i$ and $j$, $n$ is the total number of features and

$$
\begin{aligned}
\bar X &= \frac{\sum_{j=1}^n x_j}{n},\\
S &= \sqrt{\frac{\sum_{j=1}^n x_j^2}{n} - (\bar X)^2}.\\
\end{aligned}
$$

The $G_i^*$ is a $z$-score.

There are three things to consider when undertaking any hot spot analysis:

1.  The hot spot analysis tool assesses whether high or low values (the number of crimes, accident severity, or dollars spent on sporting goods, for example) cluster spatially. The field containing those values is your Analysis Field. For point incident data, however, you may be more interested in assessing incident intensity than in analyzing the spatial clustering of any particular value associated with the incidents. In that case, you will need to aggregate your incident data prior to analysis.

    -   If you have polygon features, count the number of events in each polygon.
    -   Create a grid of polygons and count events in each polygon.
    -   Snap points close to each other together.

2.  They recommend fixed distance band.

3.  What is the question?

    This may seem obvious, but how you construct the Input Field for analysis determines the types of questions you can ask. Are you most interested in determining where you have lots of incidents, or where high/low values for a particular attribute cluster spatially? If so, run Hot Spot Analysis on the raw values or raw incident counts. This type of analysis is particularly helpful for resource allocation types of problems. Alternatively (or in addition), you may be interested in locating areas with unexpectedly high values in relation to some other variable. If you are analyzing foreclosures, for example, you probably expect more foreclosures in locations with more homes (said another way, at some level, you expect the number of foreclosures to be a function of the number of houses). If you divide the number of foreclosures by the number of homes, then run the Hot Spot Analysis tool on this ratio, you are no longer asking Where are there lots of foreclosures?; instead, you are asking Where are there unexpectedly high numbers of foreclosures, given the number of homes? By creating a rate or ratio prior to analysis, you can control for certain expected relationships (for example, the number of crimes is a function of population; the number of foreclosures is a function of housing stock) and identify unexpected hot/cold spots.

4.  Distance band:

    -   All features should have at least one neighbor.
    -   No feature should have all other features as neighbors.
    -   Especially if the values for the Input Field are skewed, you want features to have about eight neighbors each.

#### Distances

Inverse distance and inverse distance squared are most appropriate with continuous data or to model processes where the closer two features are in space, the more likely they are to interact/influence each other. You should always try to include a Distance Band or Threshold Distance value when using the inverse distance conceptualizations.

Other options:

-   contiguity: edges only or edges and corners -- for rectangular polygons or polygons which share boundaries

-   k-nearest neighbors -- when we need a minimum number of neighbors

-   Voronoi (Delaunay) triangulation

The fixed distance bands work well for point data (default in ArcGis). Select it

-   based on what you know about the geographic extent of the spacial processes prompting the clustering

-   distance bands large enough to ensure all features will have at least one neighbor, especially if the data is skewed

-   if the previous one has thousands of neighbors in some features, use it without outliers

-   use a distance band that reflect maximum spatial autocorrelation (global Moran's I?)

#### Follow-up

<https://www.esri.com/arcgis-blog/products/product/analytics/spatial-statistics-resources/?rmedium=redirect&rsource=blogs.esri.com/esri/arcgis/2010/07/13/spatial-statistics-resources>

#### Example of analysis: Crime Rate Hotspots in Euclidean space

source: <https://www.esri.com/news/arcuser/0405/ss_crimestats1of2.html>

Data: crime count per census block.

### Spatial Data Mining I: Essentials of Cluster Analysis

source: <https://www.youtube.com/watch?v=qQNOlfOYtyw>

It may be problematic when polygons have different sizes, at least unless the value is not some rate (i.e., not count or sum).

The tool does not ask where are the highest values, but we are testing for randomness.

### Lee--Khattak: Case Study of Crash Severity Spatial Pattern Identification in Hot Spot Analysis, 2019

Goal: "building a framework for identifying significant spatial clustering patterns characterized by crash severity". They use Getis-Ord $G_i^*$ in ArcGis 10.6.

They claim 3, but better 6 yeas of crash data is needed. They use 7 years. They shifted accidents to the nearest road segment by NearAnalysisTool. They use KABCO scale for severity levels of each crash and values in USD (death / incapacitating injury / evident injury / pain and minor injury / property damage only (the same for all)). The use a city map plus its buffer (because of border effects).

Their version of Getis-Ord $G_i^*$:

$$
G_i^* = \frac
    {\sum_{j=1}^n w_{ij} x_j - 
        \left(\frac{\sum_{j=1}^n x_j}{n}\right) \times \sum_{j=1}^n w_{ij}}
    {\sqrt{\frac{\sum_{j=1}^n x_j^2 - \sum_{j=1}^n x_j}{n}} \times
        \sqrt{\frac{n \sum_{j=1}^n w_{ij}^2 - \left(\sum_{j=1}^n w_{ij}\right)^2}{n-1}}},
$$

where $x_j$ is an attribute value of an adjacent feature, $w_{ij}$ is the spatial weight between feature $i$ and $j$, and $n$ is the total number of features. $G_i^*$ is a $z$-score of each target feature. Features with statistically significant positive $z$-score (red spots) are surrounded by other high feature values. A larger potion $z$-score indicate a higher degree of clustering.

They have chosen the band width as the width in interval 2, 2.25, 2.5, ..., 9 km that maximized the global Moran's $I$. Moran's $I$ has two peaks. They chose 2.5 km and increased it to 2.7 km so that each feature had at least 8 neighbors. To save computer memory they restricted the maximum number of neighbors to 100.

They used driving distances. They use weights: $w_{ij}=1$ if $i \neq j$ and $i$ and $j$ are close; it is zero otherwise. (This is not $G_i^*$, but $G_i$.)

Their features were points of accidents.

They used three levels of statistical significance: 90%, 95%, and 99%, both for positive and negative $z$-scores.

They don't say how they constructed the clusters, only that it must have been at least 8 points with $p \leq 0.01$. They constructed high-severity and low-severity crash clusters.

"A drawback of the local spatial autocorrelation approach is the lack of a reliable indicator to measure the size and thickness of each cluster. Since clusters are represented by multiple points, they cannot be easily quantified along the links. Also, cluster boundaries are hard to distinguish as clusters are defined by points. Thus, density estimation is needed to display concentration of points along roadways and for boundary establishment."

They used network KDE, too. They used lixels of 25 m -- they estimated the number of crashes per 25. m.

They use NKDE to draw high- and low-severity crash points obtained from Getis-Ord: "Identified high and low severity crash points were drawn using the NKDE method to be estimated quantitatively as shown in Figure 5. The results of the NKDE approach presented clear boundaries for each cluster and provided more detailed clustering patterns with the width variable. From the figure, it was noted that several smallscaled clusters appeared, which were not noticeable in the local spatial autocorrelation analysis. Previously, these were excluded because of the small number of crashes (less than eight) within each cluster."

They measure the clusters obtained from NKDE on Getis-Ord significant points with two measures: 1) total distance (i.e., total length) of the cluster and 2) sum of densities within the clusters. These measures gives different orders. They don't say how they established the borders of the clusters; but on pre-filtered accidents, they may have obvious borders -- and the density is zero outside them.

### Yamada a Thill: Local Indicators of Network-Constrained Clusters in Spatial Patterns Represented by a Link Attribute, 2010

Odvození ILINCS a GLINICS. Je to fakticky jen local Moran's I nebo local Getis-Ord Gi\*, kde váhová matice je daná vzdáleností na síti. Dvě možnosti: buď jen sousedi (tj. lixely, které sdílí stejný uzel) mají $W_{ij}=1$ a zbytek 0, nebo dáno vzdáleností po síti. Protože to nemá žádné jasné rozdělení, musí se statistická významnost počítat pomocí bootstrapu. Navrhují různé verze bootstrapu: buď generují nehody nově se známou pravděpodobností, nebo permutují počty nehod na lixelu.

Uvažují dvě varianty: 1) se pracuje se skutečnými nehodami, nebo 2) s počty nehod upravenými o pravděpodobnost, že tam nehoda nastane (což je podle nich lepší). To druhé může souviset s délkou lixelu (nemusí být stejná), intenzitou dopravy a vlastností silnice (povrch, opravy, ...).

Doporučují použít současně ILINCS (local Moran's I na síti) i GLINCS (local Getis-Ord Gi\*) na síti. To první řekne, zda jsou tam podobné úseky vedle sebe, to druhé, jestli je tam hodně nebo málo nehod.

Ukazují to na nehodách na krákté silniční síti na západ od Buffalo, stát New York; nehody za 1 rok, jen ty, které je ze zákona nezbytné hlásit (ty ostatní jsou asi underrepresented). Silnice rozdělili na křižovatkách a pak na úseky 0.1 míle (tj. ne nutně stejně dlouhé). Váhy do ILINC a GLINC byly takové, že sousední lixely měly váhu 1 a jinak 0. Měli dvě varianty: jednou na lixely nalepili počet nehod, podruhé standardizovaný počet nehod.

### Ulak etal.: Exploring alternative spatial weights to detect crash hotspots, 2019

Srovnává metody detekce hotspotů na síti: Getis-Ord Gi\*, Local Moran's I a různé verze lokální K-Funkce na síti. Tvrdí, že na nehody je nejlepší local Moran's I s váhami na základě vzdálenosti.

Nehody do vzdálenosti 15 m byly agregovány, takže zbyl puntík a počet nehod. Getis-Ord Gi\* a local Moran's I počítáno podle normálních vzorců. Feature jsou body (agregovaných) nehod (asi, neříkají to úplně jasně). Použili dva druhy vah: 1) $w=1$, pokud vzdálenost byla menší než práh, a 0 jinak a 2) $w=1/d$, pokud vzdálenost $d$ byla menší než práh, a 0 jinak. To první použili pro Getis-Ord Gi\*, Moran's I a lokální K-funkci po síti, to druhé jen pro lokální K-funkci po síti. Bandwidth (zde prahová vzdálenost) byla 300 m po silnici nebo 18 s jízdy. Hotspoty u Getis-Ord Gi\* a local Moran's I určili na základě jejich $z$-score, tj. podle jejich statistické významnosti. Neřeší významnost nehod (výši škody).

K porovnání používají PAI, kde ve jmenovateli je délka silnice (netuším, jak z bodů udělali délky silnic -- má to být "total length of roadway within the hotspots"). Podle tohoto kritéria je nejlepší local Moran's I.

Použili ArcGis.

### Soltani a Askari: Exploring spatial autocorrelation of traffic crashes based on severity, 2017

Řeší klastry nehod pomocí local Moran's I a Getis-Ord Gi\*, a to pěti způsoby: dívají se na to, jak jsou klastrované nehody 1) všechny, 2) smrťáky, 3) úrazy, 4) jen škoda na majetku a 5) severity index. Ten počítají takto:

$$
\textrm{severity index} = \textrm{PDO} + 3 \textrm{injuries} + 9 \textrm{fatalities},
$$

kde PDO je jen škoda na majetku. Váhy vycházejí z "Iranian Ministry of Road and Urban Planning".

Feature je ale TAZ, tj. nějaká geografická oblast města, něco jako čtvrť. Pracují tedy s makrodaty a celkově je to tak k ničemu, kromě toho, že se dá citovat ten severity index.

Data jsou za několik let pro jedno Iránské město, features jsou něco jako čtvrti.

## NKDE and Extensions

### Xie--Yan: Detecting traffic accident clusters with network kernel density estimation and local spatial statistics: an integrated approach, 2013

They claim NKDE is good only for visualization "due to the missing of quantitative statistical inference assessment". Goal: integrate "NetKDE with local Moran'I for hot spot detection of traffic accidents. After density is computed for road segments through NetKDE, it is then used as the attribute for computing local Moran's I. With an NetKDE-based approach, conditional permutation, combined with a 100-m neighbor for Moran's I computation, leads to fewer statistically significant ''highhigh'' (HH) segments and hot spot clusters." "The KDE belongs to the methods examining the first-order effects of a spatial process, while Moran'I is one of the methods for examining the second-order effects of a spatial process. The combined strength of both should lead to more effective hot-spot detection. In addition, one of the major limitations for KDE and NetKDE is that no formal statistical inference is employed in the process and there is no indication of a density threshold above which a hot spot can be confidently declared (Bailey and Gatrell, 1995; Xie and Yan, 2008; Kuo et al., 2012). Applying a local statistical approach, such as local Moran's I, to density values resulting from NetKDE could provide a useful mechanism for conducting rigorous statistical tests."

NKDE: the shape of kernel is less important than the band width; they use/invented lixels.

They use local Moran's $I$ in form:

$$
I_i = z_i \sum_j w_{ij} z_j,
$$

where $z_i$ and $z_j$ are the deviation from the mean, and $w_{ij}$ is the weight.

They "analyze the hot spots of traffic accidents by examining the spatial autocorrelation of accident density values resulting from NetKDE, instead of accident points or a tabulated count at a road segment." "By conducting a statistical significance analysis on density values with local statistics such as local Moran's I, it is possible to evaluate formally the statistical significance of the extensiveness of locations with high density values, and to determine if hot spots of traffic accidents indeed exist consistently along certain portions of a roadway network." The "distribution of local Moran's I values is established with a large number or runs of Monte Carlo simulations" of two types.

They use only "high-high" (HH) spatial autocorrelation = locations with high values surrounded by neighboring locations also with high values (hot spots), which could be statistically unusual. These are locations ($i$) satisfying two conditions: 1) $(y_i - \bar y) > 0$ and $\sum_j w_{ij} (y_j - \bar y) > 0$, where $y_j$ is the NetKDE density value at the $j$th neighbor location of location $i$.

Clusters are created this way: "The aggregation is performed by merging significant segments with their direct significant neighbors."

They use lixel of 10 m length and Quartic kernel with band width 100 m.

They don't use accident severity.

### Le, Liu, and Lin: Traffic accident hotspot identification by integrating kernel density estimation and spatial autocorrelation analysis: a case study, 2022

Goal: They create an "approach that integrated kernel density estimation (KDE) algorithm and spatial autocorrelation analysis, which helped to determine traffic accident (TA) hotspot locations and simultaneously evaluate the statistical significance of the hotspot clusters. Firstly, hotspots were identified by applying a GIS-based KDE algorithm. Secondly, the hotspot clusters were evaluated in terms of statistical significance by applying the Moran's I statistic indices. Finally, hotspots were arranged according to their significance."

Reason: KDE methods lack an evaluation of the statistical significance of the determined hotspots.

"The aim of our study was to evaluate the statistical significance of TA hotspots that were determined by KDE method in case of taking into account SI."

"firstly, the planar KDE method was applied to determine the TA hotspot locations. Secondly, the statistical significance of the hotspots was evaluated by applying global and local Moran's I methods. Finally, their orders were organized according to their dangerous levels. The results were then validated to equivalent property damage only (EPDO) method and Getis-Ord Gi\* statistics."

Methodology:

1.  They geocoded traffic accidents (TA). They aggregated TAs that happened in the same place. (Co byl výsledek? Buňky s počty? Netuším.)
2.  They "considered" SI in determining TA hotspots. (Neříkají jak.)
3.  They used planar KDE to create a TA density map.
4.  They calculated global Moran's I to prove TAs are not distributed randomly. They used the Moran's I iteratively to find the best bandwidth.
5.  The "significant map of clusters" was generated by local Moran's I.
6.  A TA hotspots priority map was produced as a result of the combination between the TA density map and the significant map of clusters.
7.  To validate the proposed methodology, the obtained results were compared to the Getis--Ord Gi\* and EPDO method.

Details:

-   Severity index $SI = 10I + 40D$, where $I$ is the total number of injuries and $D$ is the total number of deaths.

-   They used planar KDE, Quartic kernel.

-   Global Moran's I was computed on point events (accidents).

-   Local Moran's I---they don't say what was the feature. The formula was $I_i = z_i \sum_{j=1}^n w_{i,j} z_j$, where $z_i$ is the deviation from the mean and $w_{ij}$ is the spatial weight.

-   Getis--Ord Gi\* for location of HH clusters. They don't say what were the features.

-   EPDO: Equivalence property damage only method was used for hotspots ranking. They calculated weights as accident expenditure for accident severity divided by expenditure on property damage only. They have weights: fatal = 40, injury = 10, property damage only = 1 (based on VSL and average property damage). Total EPDO Score = sum of weight for fatality (40) \* number of fatalities + weight for injuries (10) \* number of injuries + weight for property damage (1) \* number of property damages. This score is used to rand locations in descending order.

KDE: They used planar KDE "to create a TA density map in case of taking into account accident SI." (Neříkají jak, ale mluví o "cell size" a "search radius (bandwidth)".) They use 1000 m bandwidth because of previous studies. (Vypadá to, že rozdělili oblast na buňky. Co je buňka? Je to pixel v planárním KDE? Nebo v každé buňce spočítali výši škod SI. KDE sjeli na buňkách -- ale nevím, jak. Tohle IMHO KDE neumí. Jak je to v ArcGisu?)

KDE lacks an evaluation of the statistical significance to determine hotspots. They want to evaluate the hotspot's statistical significance, find out the most hazardous locations with statistical significance, and rank them according to their dangerous levels. They use Moran's I for this. Global Moran's I rejects that accidents happen randomly. They use it iterativly to find bandwidth for local Moran's I -- they started at 500 m and selected 2250 m. (Není jasné, co tu byl feature. Snad pixel s hustotou KDE?)

They chose statistically significant "HH-points" where a high number of accidents are surrounded by high values. (Našli i LL, LH a HL "body" -- HL je vysoký obklopený nízkými, čili "outlier".)

In the next step, the TA density map and the significant map of clusters were overlapped together. (Neříkají jak.) They use HH "points" only. The figure shows that "there were several of the TA hotspots determined by the KDE were not really dangeorus." Her, "to identify the best arrangement of TA density in different classes, we apply the natural-brakes (Jenks) classification technique."

They used Getis--Ord Gi\* to validate the HH clusters. They calculated Gi\* $z$-score and $p$-value "per feature" (ale zase neříkají, co je feature!). They used EPDO method here. The results of this ranking was quite similar to the major methodology.

Podle nich to dokazuje, že planární KDE je ve městě s vysokou husotou silnic ok.

## Mix of Getis-Ord and NKDE

### Manepalli--Bham--Kandada: EVALUATION OF HOTSPOTS IDENTIFICATION USING KERNEL DENSITY ESTIMATION (K) AND GETIS-ORD (Gi\*) ON I-630, 2011

Porovnává KDE a Getis-Ord Gi\*. Data: sedm let na I-630 (7.4 míle) v Arkansasu. Hotspot definuje jako "a section of a highway that have an accident frequency significantly higher than expected at some threshold level of significance."

Getis-Ord Gi\* definuje standardně, používá jeho $z$-score. Hotspoty určuje na základě $z$-score, které dělí s použitím "natural breaks and based on the Jenks's algorithm." "This algorithm generates a series of values that best represent the actual breaks observed in the data, as opposed to some arbitrary classificatory scheme; thus, it preserves true clustering of data values. Further, the algorithm creates $k$ classes so that the variance within categories is minimized. In this study, the categorization was carried out in two categories, i.e., high and low."

Getis-Ord Gi\* asi počítají na bodech; používají "inverse square distance." Každý bod dostává váhu podle závažnosti odvozené od převodu na peníze přes VSL. Fatality (\$4,008,900), major injury (\$216,000), minor injury (\$79,000), stížnost na bolest (\$44,900) a property damage only (\$7,400). Z toho spočítají váhy událostí jako podíl dané hodnoty a průměrné škody na majetku. Váha smrti je tak $4008900 / 7400 = 542$.

Tvrdí, že hotspoty nalezené pomocí KDE a Gi\* jsou podobné. Tvrdí, že Gi\* závisí na hustotě. KDE je speciální případ hustoty.

Neříkají ale, jak počítali KDE (ani jestli na síti, nebo v prostoru -- používají ArcGis, nemluví o rozšíření, což by vypadalo spíš jako v prostoru). Taky neříkají, jak konstruovali KDE hotspoty -- možná taky podle Jenks.

### Nie et al.: A Network-Constrained Integrated Method for Detecting Spatial Cluster and Risk Location of Traffic Crash: A Case Study from Wuhan, China, 2015

Nejdřív odhadnou NKDE (podle Okabe) a pak zjišťují statistickou významnost NKDE pomocí GLINCS, což je nějaká odvozenina od Getis-Ord Gi\*. Data jsou nehody ve Wuhanu za rok 2007 (jeden rok). Z nehod používají jen pozici. Silnice vzali "main roadways, secondary roadways and branch roads and excluded metro-ways, highways, railways and ferry-ways." Software je ArcGis a GeoDaNet.

GLINCS je odvozeno z Getis-Ord Gi\* a měří autokorelaci a koncentraci stejnou základní rovnicí jako Getis-Ord Gi\*, ale má jinou váhovou matici $W$. "In GLINCS, the network is split into smaller segments to better reflect characteristics of the scale of research data and research area. $W_{ij}$ is defined as connectivity between segment $i$ and $j$ and can designate whether segment $i$ and segment $j$ share a common node. The value indicates the autocorrelation and concentraion value around the interest observed link $i$ ($i=1, \ldots, n$)." Používají k získání statistické významnosti NKDE. Zároveň nějak použili k získání stat. významnosti 99 iterací Monte Carlo ("conditional permutation process -- ale to možná jen pro srovnávací modely bez NKDE?).

Zkusili tři nastavení: lixely délky 10 m a bandwidth 40 m, lixely délky 10 m a bandwidth 200 m a lixely délky 40 m a bandwidth 200 m. Kernel byl vždy gaussovský. Při lixelech délky 40 m tam měli i mnoho kratších. Při bandwidth 200 m byly hustoty podobné bez ohledu na délku lixelu, takže se celkové součty hustot lišily. Dál používali jen bandwidth délky 200 m. Významné lixely hledali přes $z$-score při $p$-hodnotách 0.01, 0.05 a 0.1. Navíc hledali statisticky významné segmenty silnic se stejným jménem/číslem.

Kromě toho zkoušeli použít Getis-Ord Gi\* přímo na lixelech délky 10 a 40 m. Nenašlo jim to žádné klastry nehod.

## Hierarchické klastry

### Sugihara et al.: Computational methods for the point cluster analysis on networks, 2011

Metody hledání hierarchických klastrů na sítích. Myšlenka je jednoduchá: Na začátku je každý bod vlastní klastr. Pak spoj dva nejbližší klastry, pak další dva nejbližší, atd., až vznikne hierarchický strom. Nejbližší může znamenat 1) vzdálenost mezi dvěma nejbližšími body v klastrech, 2) vzdálenost mezi dvěma nejvzdálenějšími body ve dvou klastrech, nebo 3) průměrnou vzdálenost. Pro potřeby nehod se mi jako nejlepší jeví ta první.

Kromě toho mají i algoritmy, jak efektivně klastry konstruovat.

## Posuvná okna (moving-segment approach)

### Steenberghen, Aerts a Thomas: Spatial clustering of events on a network, 2010

Na silniční síť umístí hromadu bodů: body jsou na křižovatkách a pak rozdělí i dlouhé segmenty silnic. Na těchto bodech počítají "dangerousness index" $DI_i = \sum_{j=1}^n w_{ij} I_D(D_{ij}^N)$, kde $w_{ij}$ je váha $j$-té nehody v bodě $i$, $d_{ij}^N$ je nejkratší vzdálenost po silnici mezi nehodou $j$ a bodem měření $i$ a $I_D(d_{ij}^N)$ je funkce, která je 1, pokud je vzálenost kratší než práh, a 0 jinak. Mimo body měření hodnoty lineárně aproximují.

Nehody mohou být vážny podle vzdálenosti, toho, jak jsou hrozné (severity), počtu mrtvých atd., ale v paperu používají jen váhy založené na vzdálenosti. Uvažují tři: 1) distance band (1, pokud vzdálenost kratší než práh $D^N$, a 0 jinak), 2) inverzní vzálenost $w_{ij} = 1/d_{ij}^N$ a 3) lineární pokles $w_{ij} = (D^N - d_{ij}^N)/D^N$. Reálně implementují jen tu poslední. Vzdálenosti hledají rekurzivně. Implementovali to v Javě a na Bruselu to běží asi 1 minutu.

Dělají to na Bruselu, asi 1 milion lidí, 162 km${}^2$ a 1600 km silnic rozdělených do 12 000 segmentů s 7616 křižovatkami. Nehody mají za tři roky (1997 at 1999). Berou jen nehody se smrťáky, protože ty ostatní nejsou hlášené systematicky. Asi třetinu nehod vyřadili, protože nebyla dobře geolokovaná. Body měření přidali po maximálně 50 m (metoda je nemusí mít stejně dlouhé). Tak mají 35,915 bodů měření. (Vzdálenosti ale v algoritmu měří jen oproti křižovatkám, kterých je 7000.) Maximální vzdálenost $D^N$ nastavili na 50 m (zkouší od 25 do 500 m).

Statistickou významnost řeší via Monte Carlo, 1000 replikací, při kterých náhodně přehází polohy nehod.

## Jiné

### Coll et al.: Hotspots identification and ranking for road safety improvement: An alternative approach

Přehled způsobů, jak se agreguje strašnost nehod ("Composite Safety Performance Index", CSPI) a návrh nové strašně složité metody. Pro nás asi irelevantní.

## Review papery

### Ziakopoulos---Yannis: A review of spatial approaches in road safety, 2020

Review různých přístupů včetně KDE a NKDE. Necituje ale novější NKDE papery. Za důležité závěry pro NKDE považuje:

-   délka lixelu je důležitější než volba kernelu
-   bandwidth kriticky ovlivňuje distribuci hustot
-   širší bandwidth se hodí víc pro non-urban oblasti, kde je hustota nehod nižší

Užitečné jen jako odkaz do rešerše literatury k přehledu metod.

### Yao, Loo a Yang: Traffic collisions in space: four decades of advancement in applied GIS, 2016

Review různých metod, jak se řeší nehody na silnicích -- nejen hledání hotspotů, ale i přilepování na silnice a hledání, jaké vlastnosti světa působí nehody. Užitečné jen jako odkaz do rešerše literatury k přehledu metod.
